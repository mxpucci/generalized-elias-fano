# Benchmark Data Output Guide

## Overview

This document describes all the data captured in the JSON benchmark results generated by `run_benchmarks.sh`.

## JSON Output Structure

### Top-Level Fields

Each JSON file contains:

```json
{
  "context": {
    "date": "2025-10-25T15:30:00+00:00",
    "host_name": "your-hostname",
    "executable": "./build/benchmarks/compression_benchmark",
    "num_cpus": 8,
    "mhz_per_cpu": 2400,
    "cpu_scaling_enabled": false,
    "caches": [...],
    "load_avg": [1.2, 1.5, 1.3],
    "library_build_type": "release",
    
    // Custom context added by run_benchmarks.sh
    "openmp": "enabled",           // or "disabled"
    "variant": "with_omp",          // or "no_omp"
    "bitvector": "sdsl",            // bitvector implementation
    "dataset": "AP"                 // dataset name
  },
  "benchmarks": [...]
}
```

### Benchmark Entry Fields

Each benchmark in the `benchmarks` array contains:

#### Standard Google Benchmark Fields

| Field | Type | Description |
|-------|------|-------------|
| `name` | string | Benchmark name (e.g., `B_GEF_Compression/AP/sdsl/APPROXIMATE/512`) |
| `family_index` | integer | Index grouping related benchmarks |
| `per_family_instance_index` | integer | Instance index within family |
| `run_name` | string | Full run identifier |
| `run_type` | string | Type: `iteration` or `aggregate` |
| `repetitions` | integer | Number of repetitions |
| `repetition_index` | integer | Current repetition (0-based) |
| `threads` | integer | Number of threads used |
| `iterations` | integer | Number of iterations performed |
| `real_time` | float | Wall-clock time in nanoseconds |
| `cpu_time` | float | CPU time in nanoseconds |
| `time_unit` | string | Time unit (usually `ns`) |

#### Custom Counter Fields

The benchmarks add custom counters specific to compression performance:

##### Compression Benchmarks

| Counter | Type | Unit | Description |
|---------|------|------|-------------|
| `num_integers` | integer | count | Number of integers in the dataset |
| `size_in_bytes` | integer | bytes | Compressed size in memory |
| `bpi` | float | bits/integer | Bits per integer (compression ratio) |
| `compression_throughput_MBs` | float | MB/s | Compression speed (1024-based) |

##### Lookup (Random Access) Benchmarks

| Counter | Type | Unit | Description |
|---------|------|------|-------------|
| `lookup_throughput_MBs` | float | MB/s | Random access throughput (1024-based) |

##### Serialization Space Benchmarks

| Counter | Type | Unit | Description |
|---------|------|------|-------------|
| `serialized_size_in_bytes` | integer | bytes | Size after serialization to disk |
| `serialized_bpi` | float | bits/integer | Bits per integer after serialization |

##### Decompression Benchmarks

| Counter | Type | Unit | Description |
|---------|------|------|-------------|
| `decompression_throughput_MBs` | float | MB/s | Full decompression speed (1024-based) |

## Benchmark Types

### 1. Compression Throughput

**Naming Pattern**: `<COMPRESSOR>_Compression`

**Examples**:
- `B_GEF_Compression/AP/sdsl/APPROXIMATE/512`
- `U_GEF_Compression/BM/sdsl/OPTIMAL/4096`
- `RLE_GEF_Compression/CT/sdsl/2048`

**Data Captured**:
- ✅ Compression time (`real_time`, `cpu_time`)
- ✅ Compressed size (`size_in_bytes`)
- ✅ Compression ratio (`bpi`)
- ✅ Compression throughput (`compression_throughput_MBs`)

**Purpose**: Measure how quickly each compressor can compress data.

### 2. Random Access (Lookup)

**Naming Pattern**: `<COMPRESSOR>_Lookup`

**Examples**:
- `B_GEF_Lookup/AP/sdsl/APPROXIMATE/512`
- `U_GEF_Lookup/BM/sdsl/OPTIMAL/4096`
- `RLE_GEF_Lookup/CT/sdsl/2048`

**Data Captured**:
- ✅ Lookup time per access (`real_time`, `cpu_time`)
- ✅ Lookup throughput (`lookup_throughput_MBs`)

**Purpose**: Measure random access performance (operator[]).

### 3. Serialization Space

**Naming Pattern**: `<COMPRESSOR>_Serialization_Space`

**Examples**:
- `B_GEF_Serialization_Space/AP/sdsl/APPROXIMATE/512`
- `U_GEF_Serialization_Space/BM/sdsl/OPTIMAL/4096`
- `RLE_GEF_Serialization_Space/CT/sdsl/2048`

**Data Captured**:
- ✅ Serialized file size (`serialized_size_in_bytes`)
- ✅ Serialized compression ratio (`serialized_bpi`)

**Purpose**: Measure actual disk space requirements after serialization.

**Note**: These benchmarks run with `Iterations(1)` since they only need to measure size once.

### 4. Decompression Throughput

**Naming Pattern**: `<COMPRESSOR>_Decompression`

**Examples**:
- `B_GEF_Decompression/AP/sdsl/APPROXIMATE/512`
- `U_GEF_Decompression/BM/sdsl/OPTIMAL/4096`
- `RLE_GEF_Decompression/CT/sdsl/2048`

**Data Captured**:
- ✅ Full decompression time (`real_time`, `cpu_time`)
- ✅ Decompression throughput (`decompression_throughput_MBs`)

**Purpose**: Measure how quickly the entire dataset can be decompressed using `get_elements(0, size)`.

**OpenMP Impact**: This is where the main difference between `with_omp` and `no_omp` variants will be visible for large partition counts.

## Compressor Variants

### B_GEF (with RLE)
- Split point strategies: `APPROXIMATE_SPLIT_POINT`, `OPTIMAL_SPLIT_POINT`
- Partition sizes: 512, 1024, 2048, 4096, 8192, 16384, 32768
- All benchmark types: Compression, Lookup, Serialization Space, Decompression

### B_GEF_NO_RLE (without RLE)
- Same configuration as B_GEF
- Used to compare RLE effectiveness

### U_GEF
- Split point strategies: `APPROXIMATE_SPLIT_POINT`, `OPTIMAL_SPLIT_POINT`
- Partition sizes: 512, 1024, 2048, 4096, 8192, 16384, 32768
- All benchmark types: Compression, Lookup, Serialization Space, Decompression

### RLE_GEF
- **No split point strategy** (not applicable)
- Partition sizes: 512, 1024, 2048, 4096, 8192, 16384, 32768
- All benchmark types: Compression, Lookup, Serialization Space, Decompression

## Total Benchmarks Per Dataset

For each dataset file, the benchmark suite runs:

| Compressor | Strategies | Partition Sizes | Benchmark Types | Total |
|------------|-----------|-----------------|-----------------|-------|
| B_GEF | 2 | 7 | 4 | 56 |
| B_GEF_NO_RLE | 2 | 7 | 4 | 56 |
| U_GEF | 2 | 7 | 4 | 56 |
| RLE_GEF | 1 | 7 | 4 | 28 |
| **Total** | | | | **196** |

With **both OpenMP variants** (with_omp + no_omp), that's **392 benchmarks per dataset**.

For **16 datasets**, that's **6,272 total benchmark runs**.

## Example JSON Excerpt

```json
{
  "context": {
    "date": "2025-10-25T18:30:00+00:00",
    "host_name": "macbook-pro",
    "executable": "./build/benchmarks/compression_benchmark",
    "num_cpus": 10,
    "mhz_per_cpu": 3200,
    "openmp": "enabled",
    "variant": "with_omp",
    "bitvector": "sdsl",
    "dataset": "AP"
  },
  "benchmarks": [
    {
      "name": "B_GEF_Compression/0/1/4096",
      "family_index": 0,
      "per_family_instance_index": 0,
      "run_name": "B_GEF_Compression/0/1/4096",
      "run_type": "iteration",
      "repetitions": 1,
      "repetition_index": 0,
      "threads": 1,
      "iterations": 5,
      "real_time": 1250000000.0,
      "cpu_time": 1248000000.0,
      "time_unit": "ns",
      "num_integers": 10000000,
      "size_in_bytes": 15625000,
      "bpi": 12.5,
      "compression_throughput_MBs": 64.0
    },
    {
      "name": "B_GEF_Decompression/0/1/4096",
      "family_index": 4,
      "per_family_instance_index": 0,
      "run_name": "B_GEF_Decompression/0/1/4096",
      "run_type": "iteration",
      "repetitions": 1,
      "repetition_index": 0,
      "threads": 1,
      "iterations": 10,
      "real_time": 500000000.0,
      "cpu_time": 498000000.0,
      "time_unit": "ns",
      "decompression_throughput_MBs": 160.0
    }
  ]
}
```

## Data Analysis

### Extracting Specific Metrics

Using `jq` to query JSON files:

```bash
# Get all decompression throughput for B_GEF with partition size 4096
cat AP_with_omp.json | jq '.benchmarks[] | select(.name | contains("B_GEF_Decompression") and contains("4096")) | {name, decompression_throughput_MBs}'

# Get compression ratios for all compressors
cat AP_with_omp.json | jq '.benchmarks[] | select(.name | contains("Serialization_Space")) | {name, serialized_bpi}'

# Compare OpenMP vs no-OMP for decompression
cat AP_with_omp.json | jq '.benchmarks[] | select(.name | contains("Decompression")) | {name, throughput: .decompression_throughput_MBs}' > with_omp_decompression.json
cat AP_no_omp.json | jq '.benchmarks[] | select(.name | contains("Decompression")) | {name, throughput: .decompression_throughput_MBs}' > no_omp_decompression.json
```

### Finding Best Configuration

```bash
# Find best compression ratio (lowest bpi)
cat AP_with_omp.json | jq '[.benchmarks[] | select(.serialized_bpi) | {name, bpi: .serialized_bpi}] | sort_by(.bpi) | first'

# Find fastest decompression
cat AP_with_omp.json | jq '[.benchmarks[] | select(.decompression_throughput_MBs) | {name, throughput: .decompression_throughput_MBs}] | sort_by(.throughput) | reverse | first'

# Find best compression/decompression balance
# (lowest bpi with highest decompression throughput)
```

### Comparing OpenMP Impact

```bash
# Compare same benchmark across variants
BENCHMARK_NAME="B_GEF_Decompression/0/1/4096"

WITH_OMP=$(cat AP_with_omp.json | jq ".benchmarks[] | select(.name == \"$BENCHMARK_NAME\") | .decompression_throughput_MBs")
NO_OMP=$(cat AP_no_omp.json | jq ".benchmarks[] | select(.name == \"$BENCHMARK_NAME\") | .decompression_throughput_MBs")

echo "With OpenMP: ${WITH_OMP} MB/s"
echo "No OpenMP: ${NO_OMP} MB/s"
echo "Speedup: $(echo "scale=2; $WITH_OMP / $NO_OMP" | bc)x"
```

## Validation

### Verifying Complete Data

To ensure all expected benchmarks ran successfully:

```bash
# Count total benchmarks
cat AP_with_omp.json | jq '.benchmarks | length'
# Expected: 196 (or close, depending on iterations/repetitions)

# Check for missing benchmark types
cat AP_with_omp.json | jq '[.benchmarks[].name | split("/")[0]] | unique'
# Expected: ["B_GEF_Compression", "B_GEF_Lookup", "B_GEF_Serialization_Space", 
#            "B_GEF_Decompression", "B_GEF_NO_RLE_Compression", ...]

# Verify all counters are present
cat AP_with_omp.json | jq '.benchmarks[0] | keys'
```

### Checking for Errors

```bash
# Google Benchmark includes error messages in JSON if benchmarks fail
cat AP_with_omp.json | jq '.benchmarks[] | select(.error_message) | {name, error: .error_message}'
```

## Using the Data for Publications

### Key Metrics for Papers

1. **Compression Ratio** (lower is better):
   - Use `serialized_bpi` from Serialization_Space benchmarks
   - Reports actual disk space usage

2. **Compression Speed** (higher is better):
   - Use `compression_throughput_MBs` from Compression benchmarks
   - Measures MB/s for building the data structure

3. **Query Performance** (higher is better):
   - Use `lookup_throughput_MBs` from Lookup benchmarks
   - Measures random access speed

4. **Decompression Speed** (higher is better):
   - Use `decompression_throughput_MBs` from Decompression benchmarks
   - Measures full dataset decompression speed
   - **Important**: Compare with_omp vs no_omp to show parallelization benefit

### Creating Tables

The JSON data can be processed into LaTeX tables using the provided Python scripts in `scripts/`:

```bash
# Generate LaTeX tables from JSON results
python3 scripts/bench_tables.py benchmark_results/
```

This will create tables in `latex_tables/` directory.

## Troubleshooting

### Missing Counters

If custom counters are missing from the JSON output:
- Check that benchmarks completed successfully (no error_message field)
- Verify the benchmark implementation in `compression_benchmark.cpp` sets the counters

### Incomplete Results

If the JSON file is truncated or incomplete:
- Check disk space
- Review stderr output (captured in JSON files by the script's `2>&1` redirection)
- Increase `--benchmark_min_time` if benchmarks are finishing too quickly to measure accurately

### Performance Anomalies

If results seem inconsistent:
- Ensure the system isn't under load (check `load_avg` in context)
- Verify CPU frequency scaling is disabled (`cpu_scaling_enabled: false`)
- Run multiple repetitions: `--benchmark_repetitions=5`
- Check that other processes aren't interfering

## Related Documentation

- [run_benchmarks.sh](./run_benchmarks.sh) - Benchmark runner script
- [OPENMP_BENCHMARKS.md](./OPENMP_BENCHMARKS.md) - OpenMP benchmark variants
- [compression_benchmark.cpp](./benchmarks/compression_benchmark.cpp) - Benchmark implementation
- [Google Benchmark JSON Output](https://github.com/google/benchmark/blob/main/docs/user_guide.md#output-formats)

